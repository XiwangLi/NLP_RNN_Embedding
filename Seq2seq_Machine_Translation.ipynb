{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2seq_Machine_Translation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "1h22OBSAvC-e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from random import randint\n",
        "from numpy import array\n",
        "from numpy import argmax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "toW6ibHmvy3H",
        "colab_type": "code",
        "outputId": "7618ac2d-188d-442f-e1fa-09604b5a42ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "from random import randint\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "\n",
        "# generate a sequence of random integers\n",
        "def generate_sequence(length, n_unique):\n",
        "\treturn [randint(0, n_unique-1) for _ in range(length)]\n",
        "\n",
        "# one hot encode sequence\n",
        "def one_hot_encode(sequence, n_unique):\n",
        "\tencoding = list()\n",
        "\tfor value in sequence:\n",
        "\t\tvector = [0 for _ in range(n_unique)]\n",
        "\t\tvector[value] = 1\n",
        "\t\tencoding.append(vector)\n",
        "\treturn array(encoding)\n",
        "\n",
        "# decode a one hot encoded string\n",
        "def one_hot_decode(encoded_seq):\n",
        "\treturn [argmax(vector) for vector in encoded_seq]\n",
        "\n",
        "# prepare data for the LSTM\n",
        "def get_pair(n_in, n_out, n_unique):\n",
        "\t# generate random sequence\n",
        "\tsequence_in = generate_sequence(n_in, n_unique)\n",
        "\tsequence_out = sequence_in[:n_out] + [0 for _ in range(n_in-n_out)]\n",
        "\t# one hot encode\n",
        "\tX = one_hot_encode(sequence_in, n_unique)\n",
        "\ty = one_hot_encode(sequence_out, n_unique)\n",
        "\t# reshape as 3D\n",
        "\tX = X.reshape((1, X.shape[0], X.shape[1]))\n",
        "\ty = y.reshape((1, y.shape[0], y.shape[1]))\n",
        "\treturn X,y\n",
        "\n",
        "# generate random sequence\n",
        "X, y = get_pair(5, 2, 50)\n",
        "print(X.shape, y.shape)\n",
        "print('X=%s, y=%s' % (one_hot_decode(X[0]), one_hot_decode(y[0])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 5, 50) (1, 5, 50)\n",
            "X=[4, 22, 33, 29, 5], y=[4, 22, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zUcCN8N4wE33",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Simple encoder and decoder demo using on-hot vector"
      ]
    },
    {
      "metadata": {
        "id": "rBkFNXzJvzdv",
        "colab_type": "code",
        "outputId": "4d17c065-3ed2-4123-ad28-8a468972561c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "# generate random sequence\n",
        "sequence = generate_sequence(5, 50)\n",
        "print(sequence)\n",
        "# one hot encode\n",
        "encoded = one_hot_encode(sequence, 50)\n",
        "print(encoded)\n",
        "# decode\n",
        "decoded = one_hot_decode(encoded)\n",
        "print(decoded)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[44, 9, 41, 3, 7]\n",
            "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "[44, 9, 41, 3, 7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GwJs04S61JYn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Seq2seq with Attention in TenserFlow for Machine translation"
      ]
    },
    {
      "metadata": {
        "id": "5K7g49qjzxhc",
        "colab_type": "code",
        "outputId": "923276d3-0b99-49a1-f3bb-6679ffac0112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "# Import TensorFlow >= 1.10 and enable eager execution\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "import keras\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n",
            "2.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EI-35JgOx0yW",
        "colab_type": "code",
        "outputId": "ac4b87a0-5e1f-43f6-a9b8-ff7380b7e206",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "cell_type": "code",
      "source": [
        "! wget http://www.manythings.org/anki/fra-eng.zip\n",
        "! unzip fra-eng.zip\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-11-29 23:22:40--  http://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.24.108.196, 104.24.109.196, 2606:4700:30::6818:6cc4, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.24.108.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3305307 (3.2M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip’\n",
            "\n",
            "fra-eng.zip         100%[===================>]   3.15M  13.6MB/s    in 0.2s    \n",
            "\n",
            "2018-11-29 23:22:41 (13.6 MB/s) - ‘fra-eng.zip’ saved [3305307/3305307]\n",
            "\n",
            "Archive:  fra-eng.zip\n",
            "  inflating: _about.txt              \n",
            "  inflating: fra.txt                 \n",
            "_about.txt  fra-eng.zip  fra.txt  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aFEpjbTP1U7Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path_to_file = \"fra.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oh3aMGJ31fVn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "    \n",
        "    # creating a space between a word and the punctuation following it\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\" \n",
        "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    \n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "    \n",
        "    w = w.rstrip().strip()\n",
        "    \n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xQgd2VQ61r94",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 1. Remove the accents\n",
        "# 2. Clean the sentences\n",
        "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset(path, num_examples):\n",
        "    lines = open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "    \n",
        "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "    \n",
        "    return word_pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d6HadsvF2uTu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This class creates a word -> index mapping (e.g,. \"dad\" -> 5) and vice-versa \n",
        "# (e.g., 5 -> \"dad\") for each language,\n",
        "class LanguageIndex():\n",
        "  def __init__(self, lang):\n",
        "    self.lang = lang\n",
        "    self.word2idx = {}\n",
        "    self.idx2word = {}\n",
        "    self.vocab = set()    \n",
        "    self.create_index()\n",
        "    \n",
        "  def create_index(self):\n",
        "    for phrase in self.lang:\n",
        "      self.vocab.update(phrase.split(' '))\n",
        "    \n",
        "    self.vocab = sorted(self.vocab)\n",
        "    \n",
        "    self.word2idx['<pad>'] = 0\n",
        "    for index, word in enumerate(self.vocab):\n",
        "      self.word2idx[word] = index + 1\n",
        "    \n",
        "    for word, index in self.word2idx.items():\n",
        "      self.idx2word[index] = word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O1cg1O4O4ghq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n",
        "\n",
        "\n",
        "def load_dataset(path, num_examples):\n",
        "    # creating cleaned input, output pairs\n",
        "    pairs = create_dataset(path, num_examples)\n",
        "\n",
        "    # index language using the class defined above    \n",
        "    inp_lang = LanguageIndex(sp for en, sp in pairs)\n",
        "    targ_lang = LanguageIndex(en for en, sp in pairs)\n",
        "    \n",
        "    # Vectorize the input and target languages\n",
        "    \n",
        "    # Spanish sentences\n",
        "    input_tensor = [[inp_lang.word2idx[s] for s in sp.split(' ')] for en, sp in pairs]\n",
        "    \n",
        "    # English sentences\n",
        "    target_tensor = [[targ_lang.word2idx[s] for s in en.split(' ')] for en, sp in pairs]\n",
        "    \n",
        "    # Calculate max_length of input and output tensor\n",
        "    # Here, we'll set those to the longest sentence in the dataset\n",
        "    max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)\n",
        "    \n",
        "    # Padding the input and output tensor to the maximum length\n",
        "    input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor, \n",
        "                                                                 maxlen=max_length_inp,\n",
        "                                                                 padding='post')\n",
        "    \n",
        "    target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor, \n",
        "                                                                  maxlen=max_length_tar, \n",
        "                                                                  padding='post')\n",
        "    \n",
        "    return input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3cA9W7kb9Vz3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Try experimenting with the size of that dataset\n",
        "num_examples = 30000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_targ = \\\n",
        "    load_dataset(path_to_file, num_examples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lImjITc--gfx",
        "colab_type": "code",
        "outputId": "bc29f8c3-7010-4266-c16b-1cf6cb6936d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24000, 24000, 6000, 6000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "TMtX-eEu-0-v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Creat tf.data dataset for Tensorflow operation"
      ]
    },
    {
      "metadata": {
        "id": "URQjj8xA-zCU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
        "\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word2idx)\n",
        "vocab_tar_size = len(targ_lang.word2idx)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nRkjmTrrPcAD",
        "colab_type": "code",
        "outputId": "f78f6f33-077a-4716-c833-747889a828b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "N_BATCH"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "375"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "Lcrzo3JzAPx-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Attention is just adding an ativation and a softmax between encoder and decoder layers"
      ]
    },
    {
      "metadata": {
        "id": "RO3xXIWl-8E_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gru(units):\n",
        "  # If you have a GPU, we recommend using CuDNNGRU(provides a 3x speedup than GRU)\n",
        "  # the code automatically does that.\n",
        "  if tf.test.is_gpu_available():\n",
        "    return tf.keras.layers.CuDNNGRU(units, \n",
        "                                    return_sequences=True, \n",
        "                                    return_state=True, \n",
        "                                    recurrent_initializer='glorot_uniform')\n",
        "  else:\n",
        "    return tf.keras.layers.GRU(units, \n",
        "                               return_sequences=True, \n",
        "                               return_state=True, \n",
        "                               recurrent_activation='sigmoid', \n",
        "                               recurrent_initializer='glorot_uniform')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SO538NrRLyBx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = gru(self.enc_units)\n",
        "        \n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state = hidden)        \n",
        "        return output, state\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AQjZjJuCL0BD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = gru(self.dec_units)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "        # used for attention\n",
        "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "        \n",
        "    def call(self, x, hidden, enc_output):\n",
        "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "        \n",
        "        # hidden shape == (batch_size, hidden size)\n",
        "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "        # we are doing this to perform addition to calculate the score\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "        \n",
        "        # score shape == (batch_size, max_length, 1)\n",
        "        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V\n",
        "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
        "        \n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        \n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        context_vector = attention_weights * enc_output\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        \n",
        "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "        \n",
        "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        \n",
        "        # passing the concatenated vector to the GRU\n",
        "        output, state = self.gru(x)\n",
        "        \n",
        "        # output shape == (batch_size * 1, hidden_size)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        \n",
        "        # output shape == (batch_size * 1, vocab)\n",
        "        x = self.fc(output)\n",
        "        \n",
        "        return x, state, attention_weights\n",
        "        \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.dec_units))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OSTkNpw2MrZi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uo6LQ4E0M3bd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.AdamOptimizer()\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = 1 - np.equal(real, 0)\n",
        "  loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "peUHwu6XNHVu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "saving checkpoints (object-based saving)"
      ]
    },
    {
      "metadata": {
        "id": "skl-tJYaNCMh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hJCIyOtzNnTp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "Seq2seq without attention\n",
        "\n",
        "1. pass the input to Encoder, which returns encoder outputs and hidden states\n",
        "2. pass the encoder outputs to Decoder"
      ]
    },
    {
      "metadata": {
        "id": "q0Ie6cQ5NLoi",
        "colab_type": "code",
        "outputId": "faddb5fc-3ccd-47c0-9ad6-5c2c2edb4094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1207
        }
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    \n",
        "    hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "    \n",
        "    for (batch, (inp, targ)) in enumerate(dataset):\n",
        "        loss = 0\n",
        "        \n",
        "        with tf.GradientTape() as tape:\n",
        "            enc_output, enc_hidden = encoder(inp, hidden)   \n",
        "            \n",
        "            dec_hidden = enc_hidden            \n",
        "            dec_input = tf.expand_dims([targ_lang.word2idx['<start>']] * BATCH_SIZE, 1)       \n",
        "            \n",
        "            for t in range(1, targ.shape[1]):                \n",
        "                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output) # passing enc_output to the decoder                \n",
        "                loss += loss_function(targ[:, t], predictions)\n",
        "                \n",
        "                # using teacher forcing\n",
        "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "        \n",
        "        batch_loss = (loss / int(targ.shape[1]))        \n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        variables = encoder.variables + decoder.variables       \n",
        "        gradients = tape.gradient(loss, variables)\n",
        "        \n",
        "        optimizer.apply_gradients(zip(gradients, variables))\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.numpy()))\n",
        "    # saving (checkpoint) the model every 2 epochs\n",
        "    if (epoch + 1) % 2 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                        total_loss / N_BATCH))\n",
        "    print('Time taken for this epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 0.2341\n",
            "Epoch 1 Batch 100 Loss 0.2187\n",
            "Epoch 1 Batch 200 Loss 0.3373\n",
            "Epoch 1 Batch 300 Loss 0.2541\n",
            "Epoch 1 Loss 0.2390\n",
            "Time taken for 1 epoch 100.23147535324097 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.1993\n",
            "Epoch 2 Batch 100 Loss 0.1483\n",
            "Epoch 2 Batch 200 Loss 0.2038\n",
            "Epoch 2 Batch 300 Loss 0.1898\n",
            "Epoch 2 Loss 0.1705\n",
            "Time taken for 1 epoch 102.50953769683838 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.1011\n",
            "Epoch 3 Batch 100 Loss 0.1205\n",
            "Epoch 3 Batch 200 Loss 0.1216\n",
            "Epoch 3 Batch 300 Loss 0.1134\n",
            "Epoch 3 Loss 0.1290\n",
            "Time taken for 1 epoch 101.65851306915283 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.1029\n",
            "Epoch 4 Batch 100 Loss 0.0681\n",
            "Epoch 4 Batch 200 Loss 0.1235\n",
            "Epoch 4 Batch 300 Loss 0.0938\n",
            "Epoch 4 Loss 0.1053\n",
            "Time taken for 1 epoch 101.52017736434937 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.0776\n",
            "Epoch 5 Batch 100 Loss 0.0845\n",
            "Epoch 5 Batch 200 Loss 0.0839\n",
            "Epoch 5 Batch 300 Loss 0.0866\n",
            "Epoch 5 Loss 0.0901\n",
            "Time taken for 1 epoch 105.67734479904175 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.0704\n",
            "Epoch 6 Batch 100 Loss 0.1138\n",
            "Epoch 6 Batch 200 Loss 0.1083\n",
            "Epoch 6 Batch 300 Loss 0.0701\n",
            "Epoch 6 Loss 0.0791\n",
            "Time taken for 1 epoch 114.47815656661987 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.0517\n",
            "Epoch 7 Batch 100 Loss 0.0968\n",
            "Epoch 7 Batch 200 Loss 0.0943\n",
            "Epoch 7 Batch 300 Loss 0.1320\n",
            "Epoch 7 Loss 0.0735\n",
            "Time taken for 1 epoch 103.02192044258118 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.0771\n",
            "Epoch 8 Batch 100 Loss 0.0347\n",
            "Epoch 8 Batch 200 Loss 0.0687\n",
            "Epoch 8 Batch 300 Loss 0.0653\n",
            "Epoch 8 Loss 0.0710\n",
            "Time taken for 1 epoch 101.27979755401611 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.0522\n",
            "Epoch 9 Batch 100 Loss 0.0550\n",
            "Epoch 9 Batch 200 Loss 0.0795\n",
            "Epoch 9 Batch 300 Loss 0.0379\n",
            "Epoch 9 Loss 0.0676\n",
            "Time taken for 1 epoch 102.34604716300964 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0506\n",
            "Epoch 10 Batch 100 Loss 0.0238\n",
            "Epoch 10 Batch 200 Loss 0.0717\n",
            "Epoch 10 Batch 300 Loss 0.0650\n",
            "Epoch 10 Loss 0.0624\n",
            "Time taken for 1 epoch 110.6966814994812 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jo2bYQKVPB3Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Translate - Prediction"
      ]
    },
    {
      "metadata": {
        "id": "PSYKz6aYOyPH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "    \n",
        "    sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    inputs = [inp_lang.word2idx[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    \n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word2idx['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "        \n",
        "        # storing the attention weigths to plot later on\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang.idx2word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang.idx2word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "        \n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jwq25G46Pkja",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "    \n",
        "    fontdict = {'fontsize': 14}\n",
        "    \n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "def translate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
        "    \n",
        "    result, sentence, attention_plot = evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)\n",
        "        \n",
        "    print('Input: {}'.format(sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "    \n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z8ZA7ZqzPkAu",
        "colab_type": "code",
        "outputId": "b33e31c4-0658-4f8d-942e-eb73a4d13e24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        }
      },
      "cell_type": "code",
      "source": [
        "translate(u'ce film est très bon', encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> ce film est tres bon <end>\n",
            "Predicted translation: that movie very good ! <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAJhCAYAAACU+G7DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fba4f469da0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "7odlCcFgS6jI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}